27 bits are not enough for 8digit accuracy from the inequality 108  227 we are likely to conclude that we can represent 8digit decimal  floatingpoint numbers accurately by 27bit floatingpoint numbers  however we need 28 significant  bits to represent some 8digit numbers accurately  in general we can show that if 10p  2q1 then  q significant bits are always enough for pdigit decimal accuracy  finally we can define a compact  27bit floatingpoint representation that will give 28 significant bits for numbers of practical importance cacm february 1967 goldberg i b 